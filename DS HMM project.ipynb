{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming 2C using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paraemter values for the 1D keyboad are stored in global variables; you can change them\n",
    "pr_hit = 0.9\n",
    "pr_miss = 0.1\n",
    "deg_kb = 2\n",
    "\n",
    "pr_repeat = 0.3\n",
    "pr_moveOn = 0.7\n",
    "deg_sp = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Key functions implemented so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getPrTableForPossibleInitialStates(lengthOfWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C++: void getPrTableForPossibleInitialStates(lengthOfWord):\n",
    "# ==> \n",
    "# Python: getPrTableForPossibleInitialStates(prTable, lengthOfWord):\n",
    "#           return the information in the prTable directly\n",
    "def getPrTableForPossibleInitialStates(lengthOfWord):\n",
    "    missDistance = range( 1, lengthOfWord+1 )\n",
    "    exponentialDegrade = [ (1/deg_sp)**i    for i in missDistance]\n",
    "    scalingConstant = 1 / sum(exponentialDegrade)\n",
    "    return [scalingConstant*degrade for degrade in exponentialDegrade]\n",
    "    \n",
    "\n",
    "# Test the function to get the probabilities of the possible first states\n",
    "#      for a word of 3 characters (such as \"his\" in our handout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getPrTableForPossibleInitialStatesGivenTheWord(Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variant that accomplishes the same thing given a word (as a string)\n",
    "def getPrTableForPossibleInitialStatesGivenTheWord(Word):\n",
    "    missDistance = range( 1, len(Word)+1 )\n",
    "    exponentialDegrade = [ (1/deg_sp)**i    for i in missDistance]\n",
    "    scalingConstant = 1 / sum(exponentialDegrade)\n",
    "    return [scalingConstant*degrade for degrade in exponentialDegrade]\n",
    "    \n",
    "    \n",
    "# Test the function to get the probabilities of the possible first states\n",
    "#      for the word \"his\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getPrTableForPossibleNextStates(lengthOfWord_Plus1, currentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3, 0.39999999999999997, 0.19999999999999998, 0.09999999999999999]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C++ \n",
    "# void getPrTableForPossibleNextStates(double transitionPrTable[], \n",
    "#                                      int sizeOfTable, int currentState)\n",
    "# ==>\n",
    "# Python \n",
    "# getPrTableForPossibleNextStates(lengthOfWord_Plus1, currentState)\n",
    "# return the transitionPrTable\n",
    "\n",
    "def getPrTableForPossibleNextStates(lengthOfWord_Plus1, currentState):\n",
    "    statesAsIndices = range( lengthOfWord_Plus1 )\n",
    "    distances = [state - currentState for state in statesAsIndices ]\n",
    "    exponentialDegrade = [ (1/deg_sp)**i if i>0 else 0 for i in distances]\n",
    "    scalingConstant = pr_moveOn/sum(exponentialDegrade)\n",
    "    probabilitiesOfPossibleFirstStates = (\n",
    "        [ scalingConstant*degrade for degrade in exponentialDegrade] )\n",
    "    probabilitiesOfPossibleFirstStates[currentState] = pr_repeat\n",
    "    return probabilitiesOfPossibleFirstStates\n",
    "\n",
    "\n",
    "#Test the implementation\n",
    "getPrTableForPossibleNextStates(len(\"his\")+1, 0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getPrTableForPossibleNextStatesGivenWord(word, currentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3, 0.39999999999999997, 0.19999999999999998, 0.09999999999999999]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A convenient variant\n",
    "# Python \n",
    "# getPrTableForPossibleNextStates(word, int currentState)\n",
    "# return the transitionPrTable\n",
    "\n",
    "def getPrTableForPossibleNextStatesGivenWord(word, currentState):\n",
    "    lengthOfWord_Plus1 =  len(word) +1\n",
    "    statesAsIndices = range( lengthOfWord_Plus1 )\n",
    "    distances = [state - currentState for state in statesAsIndices ]\n",
    "    exponentialDegrade = [ (1/deg_sp)**i if i>0 else 0 for i in distances]\n",
    "    scalingConstant = pr_moveOn/sum(exponentialDegrade)\n",
    "    probabilitiesOfPossibleFirstStates = (\n",
    "        [ scalingConstant*degrade for degrade in exponentialDegrade] )\n",
    "    probabilitiesOfPossibleFirstStates[currentState] = pr_repeat\n",
    "    return probabilitiesOfPossibleFirstStates\n",
    "\n",
    "#Test the implementation\n",
    "currentState = 0\n",
    "getPrTableForPossibleNextStatesGivenWord(\"his\", currentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prCharGiveCharState(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability of touching x when trying to type y\n",
    "def prCharGiveCharState(x, y):\n",
    "    if x==y:\n",
    "        return pr_hit\n",
    "    \n",
    "    diffASCII = range(1,26)\n",
    "    missdist = [min(n, 26-n) for n in diffASCII ]\n",
    "    exponentialDegrade = [(1/deg_kb)**i for i in missdist]\n",
    "    constant_x= pr_miss/sum(exponentialDegrade)\n",
    "    \n",
    "    distASCII_x_y = abs( ord(x) - ord(y) ) \n",
    "    distKB_x_y = min(distASCII_x_y, 26-distASCII_x_y )\n",
    "    return constant_x* (1/deg_kb)** distKB_x_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take1SampleFrom1PrSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 1, 2, 1, 1, 1, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C++: int take1SampleFrom1PrSpace(double prTable[], int sizeOfTable)\n",
    "# ==>\n",
    "# Python: take1SampleFrom1PrSpace(prTable)\n",
    "#  the size of the table can be implicitly determined \n",
    "def take1SampleFrom1PrSpace(prTable):\n",
    "    probabilityThresholds = np.add.accumulate(prTable)\n",
    "    sample = np.random.random()\n",
    "    choice = (sample > probabilityThresholds).sum()\n",
    "    # print(\"Sample=\", sample, \",\\t choice=\", choice)\n",
    "    return choice\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "prTable = np.array([0.25, 0.5, 0.25])\n",
    "[take1SampleFrom1PrSpace(prTable) for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24969 , 0.500366, 0.249944])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use bin count to check empirical frequencies observed\n",
    "np.bincount( [take1SampleFrom1PrSpace(prTable) for i in range(1000000)] )/1000000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getKeyboardProbabilityTable\n",
    "### note: this is a simple variant of prCharGiveCharState(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C++: void getKeyboardProbabilityTable(char charToType, double prTable[])\n",
    "#==>\n",
    "#Python: getKeyboardProbabilityTable(charToType) \n",
    "#        to return the probabilities of getting a, b, ..., y, z\n",
    "#        as a numpy array\n",
    "#Note: This is simply a simple variant of prCharGiveCharState(x, y):\n",
    "\n",
    "def getKeyboardProbabilityTable(charToType):\n",
    "    #First determine the scaling constant for the exponential degrading\n",
    "    diffASCII = range(1,26)\n",
    "    missdist = [min(n, 26-n) for n in diffASCII ]\n",
    "    exponentialDegrade = [(1/deg_kb)**i for i in missdist]\n",
    "    scalingConstant = pr_miss/sum(exponentialDegrade)    \n",
    "    \n",
    "    #Set up an empty probability table \n",
    "    prTable = np.empty(26)\n",
    "    y = charToType\n",
    "    \n",
    "    # for each x in a to z,\n",
    "    # set up a loop to determine the probability of touching x \n",
    "    #     when trying to type y (i.e.charToType)\n",
    "    # store the results in the probability table accordingly\n",
    "    for i, x in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "        if x==y:\n",
    "            prTable[i] = pr_hit\n",
    "        else:\n",
    "            distASCII_x_y = abs( ord(x) - ord(y) ) \n",
    "            distKB_x_y = min(distASCII_x_y, 26-distASCII_x_y )\n",
    "            prTable[i] = scalingConstant * (1/deg_kb)** distKB_x_y \n",
    "    \n",
    "    return prTable\n",
    "\n",
    "\n",
    "#Test the implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.50045785e-02, 9.00000000e-01, 2.50045785e-02, 1.25022892e-02,\n",
       "       6.25114462e-03, 3.12557231e-03, 1.56278615e-03, 7.81393077e-04,\n",
       "       3.90696539e-04, 1.95348269e-04, 9.76741347e-05, 4.88370673e-05,\n",
       "       2.44185337e-05, 1.22092668e-05, 6.10463342e-06, 1.22092668e-05,\n",
       "       2.44185337e-05, 4.88370673e-05, 9.76741347e-05, 1.95348269e-04,\n",
       "       3.90696539e-04, 7.81393077e-04, 1.56278615e-03, 3.12557231e-03,\n",
       "       6.25114462e-03, 1.25022892e-02])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#More test on the implementation\n",
    "getKeyboardProbabilityTable('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#More test on the implementation\n",
    "getKeyboardProbabilityTable('b').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## typeOneChar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C++: char typeOneChar(char charToType)\n",
    "# Python: typeOneChar(charToType) \n",
    "#   use  take1SampleFrom1PrSpace and\n",
    "#        getKeyboardProbabilityTable to\n",
    "#   simulate typing charToType and return the resulting character pressed \n",
    "\n",
    "def typeOneChar(charToType):\n",
    "    keys = \"abcdefghijklmnopqrstuvwxyz\" \n",
    "    prTable = getKeyboardProbabilityTable(charToType)\n",
    "    indexOfKeyPressed = take1SampleFrom1PrSpace( prTable )\n",
    "    return keys[ indexOfKeyPressed ]\n",
    "\n",
    "#Test the implementatiton\n",
    "\n",
    "#Type 'a' for 10 times and see the results\n",
    "[typeOneChar('a') for i in range(10) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'x', 'a', 'a', 'a', 'a', 'a', 'a', 'b']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#More test the implementatiton\n",
    "\n",
    "#Type 'a' for 10 times under a different setting and see the results\n",
    "[typeOneChar('a') for i in range(10) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  typeOneWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C++: void typeOneWord( char word[], char output[], \n",
    "#                        bool traceON = false, int maxOutput=100)\n",
    "# Python: typeOneWord( word, trace=False )\n",
    "#      simulate the typing of the given word (a string) and\n",
    "#      return the resulted string\n",
    "\n",
    "def typeOneWord(word, trace=False):\n",
    "    #Special States\n",
    "    I_stateIndex = -1 \n",
    "    F_stateIndex = len(word)\n",
    "    \n",
    "    # Step 0: Simulation of leaving the starting state I to enter some (first) state \n",
    "    #        to enter a regular state as the current state: throw a dice\n",
    "    charOutputsObservedSofar = \"_\"\n",
    "    stateTrajectorySofar = \"I\"\n",
    "    prTable = getPrTableForPossibleInitialStatesGivenTheWord(word)\n",
    "\n",
    "    currentState_index = take1SampleFrom1PrSpace(prTable)\n",
    "    currentState_char = word[ currentState_index  ]\n",
    "\n",
    "    if trace:\n",
    "        print( \"First state reached after leaving I: (index, char)=\", \n",
    "               (currentState_index, currentState_char) \n",
    "             )\n",
    "    \n",
    "    while( currentState_index != F_stateIndex): # not the Final state F yet.\n",
    "        # Step 1: Simulation of typing a character given the current state: throw a dice\n",
    "        charTyped = typeOneChar(currentState_char)\n",
    "        charOutputsObservedSofar += charTyped\n",
    "        stateTrajectorySofar += currentState_char\n",
    "\n",
    "        if trace:\n",
    "            print( \"Current state: (index, char)=\", (currentState_index, currentState_char) )\n",
    "            print( charTyped, \" is pressed when trying to type \", currentState_char)\n",
    "            print( \"char outputs so far:\\t\", charOutputsObservedSofar )\n",
    "            print( \"state trajectory so far:\", stateTrajectorySofar )\n",
    "            print()\n",
    "\n",
    "        # Step 2: Simulation of leaving the current state to enter one of the possble next states\n",
    "        #       : throw a dice\n",
    "        prTable = getPrTableForPossibleNextStatesGivenWord(word, currentState_index)\n",
    "        nextState_index = take1SampleFrom1PrSpace(prTable)\n",
    "        nextState_char = word[ nextState_index  ] if (nextState_index<F_stateIndex) else \"F\"\n",
    "        if trace:\n",
    "            print( \"next state to enter: \", (nextState_index, \n",
    "                                             nextState_char) )\n",
    "\n",
    "        currentState_index = nextState_index\n",
    "        currentState_char = nextState_char \n",
    "\n",
    "    if trace:\n",
    "        print(\"Finish typing the word \", word)\n",
    "        print( \"char outputs:\\t\\t\", charOutputsObservedSofar+\"_\" )\n",
    "        print( \"state trajectory:\\t\", stateTrajectorySofar+\"F\" )\n",
    "        \n",
    "    return charOutputsObservedSofar[1:]\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First state reached after leaving I: (index, char)= (0, 'h')\n",
      "Current state: (index, char)= (0, 'h')\n",
      "h  is pressed when trying to type  h\n",
      "char outputs so far:\t _h\n",
      "state trajectory so far: Ih\n",
      "\n",
      "next state to enter:  (1, 'i')\n",
      "Current state: (index, char)= (1, 'i')\n",
      "i  is pressed when trying to type  i\n",
      "char outputs so far:\t _hi\n",
      "state trajectory so far: Ihi\n",
      "\n",
      "next state to enter:  (2, 's')\n",
      "Current state: (index, char)= (2, 's')\n",
      "s  is pressed when trying to type  s\n",
      "char outputs so far:\t _his\n",
      "state trajectory so far: Ihis\n",
      "\n",
      "next state to enter:  (3, 'F')\n",
      "Finish typing the word  his\n",
      "char outputs:\t\t _his_\n",
      "state trajectory:\t IhisF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'his'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_hit = 0.9\n",
    "pr_miss = 0.1\n",
    "deg_kb = 4\n",
    "\n",
    "pr_repeat = 0.1\n",
    "pr_moveOn = 0.9\n",
    "deg_sp = 4\n",
    "\n",
    "word = \"his\"\n",
    "\n",
    "#See the trace of the simulation of typing one word\n",
    "typeOneWord( word, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['his',\n",
       " 'his',\n",
       " 'gis',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'h',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hiss',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hh',\n",
       " 'jsss',\n",
       " 'hr',\n",
       " 'hiii',\n",
       " 'g',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'hj',\n",
       " 'irs',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'i',\n",
       " 'his',\n",
       " 'gs',\n",
       " 't',\n",
       " 'his',\n",
       " 'fs',\n",
       " 'hir',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'h',\n",
       " 'hiis',\n",
       " 'hiis',\n",
       " 'iss',\n",
       " 'his',\n",
       " 'ii',\n",
       " 'hks',\n",
       " 'hit',\n",
       " 'hh',\n",
       " 'hhhhis',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hss',\n",
       " 'hsss',\n",
       " 'i',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hgjs',\n",
       " 'hiss',\n",
       " 'hs',\n",
       " 'his',\n",
       " 's',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'iiit',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 's',\n",
       " 'iis',\n",
       " 'hi',\n",
       " 'iis',\n",
       " 'hhi',\n",
       " 's',\n",
       " 'hiis',\n",
       " 'is',\n",
       " 'gi',\n",
       " 'hks',\n",
       " 'gis',\n",
       " 'hhs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'gi',\n",
       " 's',\n",
       " 'hir',\n",
       " 'hks',\n",
       " 'hhis',\n",
       " 's',\n",
       " 'ii',\n",
       " 'his',\n",
       " 'iit',\n",
       " 'h',\n",
       " 'hk',\n",
       " 'h',\n",
       " 'is',\n",
       " 'is',\n",
       " 'his',\n",
       " 'ciis',\n",
       " 'hhs',\n",
       " 'hkis',\n",
       " 'hs',\n",
       " 's',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'r',\n",
       " 'iss',\n",
       " 'hhis',\n",
       " 'is',\n",
       " 'gs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 's',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'is',\n",
       " 's',\n",
       " 'hi',\n",
       " 'hhhs',\n",
       " 'hgs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'h',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hhs',\n",
       " 'hir',\n",
       " 'hii',\n",
       " 'fhis',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 's',\n",
       " 'i',\n",
       " 'hi',\n",
       " 's',\n",
       " 'hit',\n",
       " 'hs',\n",
       " 'hir',\n",
       " 'hi',\n",
       " 'hhi',\n",
       " 'hi',\n",
       " 'hh',\n",
       " 'hiss',\n",
       " 'gss',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'ehis',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'hiss',\n",
       " 'hi',\n",
       " 's',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hhiss',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'gis',\n",
       " 'hs',\n",
       " 'hhss',\n",
       " 'his',\n",
       " 'h',\n",
       " 'hs',\n",
       " 'hiis',\n",
       " 'ss',\n",
       " 'is',\n",
       " 'iisr',\n",
       " 'hs',\n",
       " 'hg',\n",
       " 'his',\n",
       " 'hhi',\n",
       " 'is',\n",
       " 'his',\n",
       " 'gis',\n",
       " 'hls',\n",
       " 'hhhis',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'iis',\n",
       " 'his',\n",
       " 'his',\n",
       " 'ijr',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hhjs',\n",
       " 'j',\n",
       " 's',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hss',\n",
       " 'i',\n",
       " 'h',\n",
       " 'his',\n",
       " 'ijt',\n",
       " 'his',\n",
       " 'his',\n",
       " 'iss',\n",
       " 'h',\n",
       " 'fis',\n",
       " 'hiis',\n",
       " 'i',\n",
       " 'ir',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'hhh',\n",
       " 'hs',\n",
       " 'ghiis',\n",
       " 'hiii',\n",
       " 'hj',\n",
       " 'i',\n",
       " 'hst',\n",
       " 'hsr',\n",
       " 'hsss',\n",
       " 'hs',\n",
       " 'i',\n",
       " 'hs',\n",
       " 'h',\n",
       " 'ks',\n",
       " 'hh',\n",
       " 'hit',\n",
       " 'hhi',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'iis',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hjs',\n",
       " 'h',\n",
       " 'hiis',\n",
       " 'ihiss',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'hiv',\n",
       " 'hhihs',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hhi',\n",
       " 'i',\n",
       " 'hir',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'i',\n",
       " 'his',\n",
       " 'ii',\n",
       " 'his',\n",
       " 'is',\n",
       " 'i',\n",
       " 'his',\n",
       " 'gis',\n",
       " 'his',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'his',\n",
       " 'i',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'is',\n",
       " 'hjjrss',\n",
       " 'ig',\n",
       " 'hhss',\n",
       " 'his',\n",
       " 'hhis',\n",
       " 'hi',\n",
       " 'hiq',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'ho',\n",
       " 'hiiu',\n",
       " 'hf',\n",
       " 's',\n",
       " 'h',\n",
       " 'hs',\n",
       " 'hgiss',\n",
       " 'it',\n",
       " 'hi',\n",
       " 'h',\n",
       " 'hhit',\n",
       " 'iss',\n",
       " 'hiisss',\n",
       " 's',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'gs',\n",
       " 'hi',\n",
       " 'hhs',\n",
       " 'hiis',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'hhis',\n",
       " 'hiss',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'hhs',\n",
       " 'hjs',\n",
       " 'hir',\n",
       " 's',\n",
       " 's',\n",
       " 'hs',\n",
       " 'gf',\n",
       " 'his',\n",
       " 'hhis',\n",
       " 'hiss',\n",
       " 'hhis',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'iss',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hjss',\n",
       " 'hisss',\n",
       " 'i',\n",
       " 'gist',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hhhis',\n",
       " 'hi',\n",
       " 'hhi',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'it',\n",
       " 'hir',\n",
       " 'js',\n",
       " 'gis',\n",
       " 'hiis',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hss',\n",
       " 'jis',\n",
       " 'h',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hir',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'h',\n",
       " 'his',\n",
       " 'iss',\n",
       " 'his',\n",
       " 'ht',\n",
       " 'hhs',\n",
       " 'jis',\n",
       " 'hs',\n",
       " 'iis',\n",
       " 'is',\n",
       " 'his',\n",
       " 'ghis',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hgs',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hirs',\n",
       " 'gs',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hhhis',\n",
       " 'isss',\n",
       " 'fi',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'hiss',\n",
       " 'h',\n",
       " 'hi',\n",
       " 'iis',\n",
       " 'hks',\n",
       " 'hist',\n",
       " 'iss',\n",
       " 'hiss',\n",
       " 'h',\n",
       " 'hfii',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'hhis',\n",
       " 'hh',\n",
       " 'hit',\n",
       " 's',\n",
       " 'hi',\n",
       " 'giis',\n",
       " 'hiss',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'hhis',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'i',\n",
       " 's',\n",
       " 'is',\n",
       " 'j',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hks',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'h',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hjs',\n",
       " 'hhs',\n",
       " 'hhs',\n",
       " 'is',\n",
       " 'his',\n",
       " 'i',\n",
       " 'hii',\n",
       " 'hs',\n",
       " 'js',\n",
       " 'hhs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'i',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'iss',\n",
       " 'i',\n",
       " 'hs',\n",
       " 'h',\n",
       " 'hs',\n",
       " 'hss',\n",
       " 'hi',\n",
       " 'hghs',\n",
       " 'hgs',\n",
       " 'is',\n",
       " 'is',\n",
       " 's',\n",
       " 'his',\n",
       " 'his',\n",
       " 'ss',\n",
       " 'hss',\n",
       " 'hi',\n",
       " 'ii',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hhiss',\n",
       " 'hii',\n",
       " 'is',\n",
       " 'his',\n",
       " 'h',\n",
       " 'i',\n",
       " 'fss',\n",
       " 's',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'his',\n",
       " 'hh',\n",
       " 'git',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'hgi',\n",
       " 'ii',\n",
       " 'is',\n",
       " 'js',\n",
       " 'is',\n",
       " 'iu',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'is',\n",
       " 'is',\n",
       " 'is',\n",
       " 'hh',\n",
       " 'hit',\n",
       " 'hhis',\n",
       " 'hit',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'his',\n",
       " 's',\n",
       " 'is',\n",
       " 'hhiis',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hit',\n",
       " 'h',\n",
       " 'hhis',\n",
       " 'h',\n",
       " 'fhiiis',\n",
       " 'his',\n",
       " 'hir',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'ih',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'i',\n",
       " 'hi',\n",
       " 'i',\n",
       " 'hhiiiq',\n",
       " 'hir',\n",
       " 'iks',\n",
       " 'hs',\n",
       " 'iiss',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'it',\n",
       " 'hi',\n",
       " 'i',\n",
       " 'i',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hh',\n",
       " 'his',\n",
       " 'i',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hig',\n",
       " 'iis',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'hi',\n",
       " 's',\n",
       " 'his',\n",
       " 'i',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'iis',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hks',\n",
       " 'ks',\n",
       " 'hhi',\n",
       " 's',\n",
       " 'ss',\n",
       " 'hk',\n",
       " 'gs',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hh',\n",
       " 'hhiss',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'f',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'his',\n",
       " 'iss',\n",
       " 'hhi',\n",
       " 'is',\n",
       " 'ss',\n",
       " 'iji',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 's',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'his',\n",
       " 's',\n",
       " 'iss',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hhhjs',\n",
       " 'hhis',\n",
       " 'is',\n",
       " 'k',\n",
       " 'hiis',\n",
       " 'h',\n",
       " 'his',\n",
       " 'hirt',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hhjs',\n",
       " 'hjs',\n",
       " 'hs',\n",
       " 'iis',\n",
       " 'gis',\n",
       " 'hjs',\n",
       " 'is',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hht',\n",
       " 'hir',\n",
       " 's',\n",
       " 'hi',\n",
       " 'hh',\n",
       " 'hr',\n",
       " 'js',\n",
       " 'is',\n",
       " 's',\n",
       " 'hi',\n",
       " 'hit',\n",
       " 'hih',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hhi',\n",
       " 'hip',\n",
       " 'hks',\n",
       " 'hiis',\n",
       " 'hir',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'i',\n",
       " 'i',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'ii',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hhi',\n",
       " 'iiis',\n",
       " 'hs',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'g',\n",
       " 'his',\n",
       " 'is',\n",
       " 'gis',\n",
       " 'i',\n",
       " 'hit',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hhs',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'fis',\n",
       " 'is',\n",
       " 'iss',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'i',\n",
       " 'gis',\n",
       " 'hir',\n",
       " 'hii',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'ii',\n",
       " 'hjs',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hhs',\n",
       " 'hir',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'his',\n",
       " 'g',\n",
       " 'gis',\n",
       " 'iss',\n",
       " 'hhs',\n",
       " 'r',\n",
       " 'hsss',\n",
       " 'his',\n",
       " 'hss',\n",
       " 'his',\n",
       " 'is',\n",
       " 'is',\n",
       " 'hg',\n",
       " 'i',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'iss',\n",
       " 'is',\n",
       " 'iii',\n",
       " 'hhi',\n",
       " 'is',\n",
       " 'gis',\n",
       " 'his',\n",
       " 'hgis',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hhs',\n",
       " 'his',\n",
       " 'hi',\n",
       " 's',\n",
       " 's',\n",
       " 'hi',\n",
       " 'hst',\n",
       " 'jis',\n",
       " 'hhgs',\n",
       " 'hhr',\n",
       " 'hhis',\n",
       " 'hi',\n",
       " 'his',\n",
       " 's',\n",
       " 's',\n",
       " 'hiiiis',\n",
       " 'hu',\n",
       " 'his',\n",
       " 'hss',\n",
       " 'hits',\n",
       " 'hiis',\n",
       " 'h',\n",
       " 'hhis',\n",
       " 'is',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'h',\n",
       " 'hiss',\n",
       " 'hhs',\n",
       " 'hi',\n",
       " 'i',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hh',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'h',\n",
       " 'hhs',\n",
       " 'hhs',\n",
       " 'h',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'hjs',\n",
       " 'hit',\n",
       " 'his',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hhis',\n",
       " 'hhk',\n",
       " 'hiss',\n",
       " 'hi',\n",
       " 'eir',\n",
       " 'his',\n",
       " 'hiiq',\n",
       " 'hii',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'iis',\n",
       " 'hjiis',\n",
       " 'iis',\n",
       " 'i',\n",
       " 'his',\n",
       " 'iu',\n",
       " 'his',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'i',\n",
       " 'ciis',\n",
       " 's',\n",
       " 'his',\n",
       " 'i',\n",
       " 'hiss',\n",
       " 'hiir',\n",
       " 'his',\n",
       " 's',\n",
       " 'h',\n",
       " 'i',\n",
       " 'is',\n",
       " 'his',\n",
       " 'h',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'gs',\n",
       " 'hhhis',\n",
       " 'h',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'hiis',\n",
       " 's',\n",
       " 'hi',\n",
       " 'iis',\n",
       " 'his',\n",
       " 'is',\n",
       " 'fs',\n",
       " 'hi',\n",
       " 's',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 's',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hiist',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'hi',\n",
       " 'hhs',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hiis',\n",
       " 'i',\n",
       " 'his',\n",
       " 'his',\n",
       " 'h',\n",
       " 'hi',\n",
       " 'is',\n",
       " 's',\n",
       " 'his',\n",
       " 'hir',\n",
       " 'hisr',\n",
       " 'his',\n",
       " 'fis',\n",
       " 'i',\n",
       " 'is',\n",
       " 'hisss',\n",
       " 'hiq',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hjs',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'i',\n",
       " 'fs',\n",
       " 'hhs',\n",
       " 'his',\n",
       " 'iiss',\n",
       " 'r',\n",
       " 'h',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hsp',\n",
       " 'his',\n",
       " 'ih',\n",
       " 'hi',\n",
       " 'it',\n",
       " 'hhis',\n",
       " 'hhis',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'j',\n",
       " 'hi',\n",
       " 's',\n",
       " 'hhi',\n",
       " 'hhs',\n",
       " 'his',\n",
       " 'hh',\n",
       " 'hhiss',\n",
       " 's',\n",
       " 'hijs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'ihis',\n",
       " 's',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'h',\n",
       " 'is',\n",
       " 'hhs',\n",
       " 'i',\n",
       " 'his',\n",
       " 'i',\n",
       " 'kis',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 's',\n",
       " 'his',\n",
       " 'h',\n",
       " 's',\n",
       " 'hhi',\n",
       " 'hiis',\n",
       " 'hs',\n",
       " 'hhs',\n",
       " 'iiss',\n",
       " 'his',\n",
       " 'hi',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the result of typing the same word 10000 times\n",
    "[typeOneWord(word, False) for i in range(10000) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basics of file input/output in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basics of file output in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data into a file. \n",
    "Lines = [\"Line 1: a;\",\"Line 2: b;\",\"Line 3: c;\"]\n",
    "\n",
    "file = open(\"outputFile1\",\"w\") \n",
    "for L in Lines:\n",
    "    file.write(L) \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load outputFile1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data into a file. \n",
    "Lines = [\"Line 1: a;\",\"Line 2: b;\",\"Line 3: c;\"]\n",
    "\n",
    "file = open(\"outputFile2\",\"w\") \n",
    "file.writelines(Lines) \n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load outputFile2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data into a file. \n",
    "Lines = [\"Line 1: a;\",\"Line 2: b;\",\"Line 3: c;\"]\n",
    "\n",
    "file = open(\"outputFile3\",\"w\") \n",
    "for line in Lines:\n",
    "    file.writelines(line +\"\\n\") \n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load outputFile3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basics of file intput in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is Line 1: a;\n",
      "Line 2: b;\n",
      "Line 3: c;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data from a file. \n",
    "file = open(\"outputFile3\",\"r\") \n",
    "x=file.read()\n",
    "print(\"x is\", x)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Line 1: a;\\n', 'Line 2: b;\\n', 'Line 3: c;\\n')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"outputFile3\",\"r\") \n",
    "x=file.readline()\n",
    "y=file.readline()\n",
    "z=file.readline()\n",
    "#show what we got in x, y, z\n",
    "x, y, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines is ['Line 1: a;\\n', 'Line 2: b;\\n', 'Line 3: c;\\n']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"outputFile3\",\"r\") \n",
    "lines=file.readlines()\n",
    "print(\"lines is\", lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Line 1: a;', 'Line 2: b;', 'Line 3: c;']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip the white spaces(i.e. spaces, tabs, and specifically'\\n' in this case)\n",
    "strippedLines = [line.strip( ) for line in lines]\n",
    "strippedLines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72  words in biolaVision.txt:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['biola',\n",
       " 'university',\n",
       " 'vision',\n",
       " 'is',\n",
       " 'to',\n",
       " 'be',\n",
       " 'an',\n",
       " 'exemplary',\n",
       " 'christian',\n",
       " 'university',\n",
       " 'characterized',\n",
       " 'as',\n",
       " 'a',\n",
       " 'community',\n",
       " 'of',\n",
       " 'grace',\n",
       " 'that',\n",
       " 'promotes',\n",
       " 'and',\n",
       " 'inspires',\n",
       " 'personal',\n",
       " 'life',\n",
       " 'transformation',\n",
       " 'in',\n",
       " 'christ',\n",
       " 'which',\n",
       " 'illuminates',\n",
       " 'the',\n",
       " 'world',\n",
       " 'with',\n",
       " 'his',\n",
       " 'light',\n",
       " 'and',\n",
       " 'truth',\n",
       " 'further',\n",
       " 'as',\n",
       " 'a',\n",
       " 'global',\n",
       " 'center',\n",
       " 'for',\n",
       " 'christian',\n",
       " 'thought',\n",
       " 'and',\n",
       " 'an',\n",
       " 'influential',\n",
       " 'evangelical',\n",
       " 'voice',\n",
       " 'that',\n",
       " 'addresses',\n",
       " 'crucial',\n",
       " 'cultural',\n",
       " 'issues',\n",
       " 'biola',\n",
       " 'university',\n",
       " 'aspires',\n",
       " 'to',\n",
       " 'lead',\n",
       " 'with',\n",
       " 'confidence',\n",
       " 'and',\n",
       " 'compassion',\n",
       " 'an',\n",
       " 'intellectual',\n",
       " 'and',\n",
       " 'spiritual',\n",
       " 'renewal',\n",
       " 'that',\n",
       " 'advances',\n",
       " 'the',\n",
       " 'purpose',\n",
       " 'of',\n",
       " 'christ']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read words from biolaVision.txt\n",
    "file = open(\"biolaVision.txt\",\"r\") \n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "\n",
    "words = [line.strip( ) for line in lines]\n",
    "\n",
    "print(len(words), \" words in biolaVision.txt:\\n\")\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implement typeOneArticle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C++: void typeOneArticle (const char * corruptedMessageFile, const char * sourceArticle, \n",
    "#                           bool trace = false);\n",
    "# Or\n",
    "# C++: void typeOneArticle (const string corruptedMessageFile, const string sourceArticle, \n",
    "#                           bool trace = false);\n",
    "# ==>\n",
    "# Python: typeOneArticle (corruptedMessageFile, sourceArticle, \n",
    "#                           trace = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeOneArticle(corruptedMessageFile, sourceArticle, trace = False):\n",
    "    file = open(sourceArticle,\"r\") \n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    words = [line.strip( ) for line in lines]\n",
    "    \n",
    "    corruptedWords = [ typeOneWord(word) for word in words]\n",
    "    if trace:\n",
    "        print( corruptedWords )\n",
    "    \n",
    "    file = open(corruptedMessageFile,\"w\") \n",
    "    for corruptedWord in corruptedWords:\n",
    "        file.writelines(corruptedWord+\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_hit = 0.6\n",
    "pr_miss = 0.4\n",
    "deg_kb = 2\n",
    "\n",
    "pr_repeat = 0.2\n",
    "pr_moveOn = 0.8\n",
    "deg_sp = 2\n",
    "\n",
    "typeOneArticle(\"corruptedVision\", \"biolaVision.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load corruptedVision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToType = \"his\"\n",
    "observedString = \"he\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State representations (excluding the special state I and F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_indicices = list( range(len(wordToType) ))\n",
    "state_indicices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'his'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_chars = wordToType\n",
    "state_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'h'), (1, 'i'), (2, 's')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = [ (state_index, state_char) for state_index, state_char in zip(  state_indicices, state_chars)]\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM representation (excluding the special state I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5714285714285714, 0.2857142857142857, 0.14285714285714285]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#At the beginning, the initial probability vector Pi after leaving the special state I\n",
    "\n",
    "vector_pi_list = getPrTableForPossibleInitialStatesGivenTheWord(wordToType)\n",
    "vector_pi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2, 0.4571428571428572, 0.2285714285714286, 0.1142857142857143],\n",
       " [0.0, 0.2, 0.5333333333333333, 0.26666666666666666],\n",
       " [0.0, 0.0, 0.2, 0.8]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transition probability matrix A (excluding the rows and columns for I and F)\n",
    "lenthOfWord = len(wordToType)\n",
    "matrix_A_List = [ getPrTableForPossibleNextStatesGivenWord(wordToType, currentState) for currentState in range(lenthOfWord)]\n",
    "matrix_A_List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4571428571428572"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the transition probability $a_{ij}$\n",
    "i = 0; j =1\n",
    "matrix_A_List[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.001562786154691411,\n",
       "  0.003125572309382822,\n",
       "  0.006251144618765644,\n",
       "  0.012502289237531288,\n",
       "  0.025004578475062576,\n",
       "  0.05000915695012515,\n",
       "  0.1000183139002503,\n",
       "  0.6,\n",
       "  0.1000183139002503,\n",
       "  0.05000915695012515,\n",
       "  0.025004578475062576,\n",
       "  0.012502289237531288,\n",
       "  0.006251144618765644,\n",
       "  0.003125572309382822,\n",
       "  0.001562786154691411,\n",
       "  0.0007813930773457055,\n",
       "  0.00039069653867285274,\n",
       "  0.00019534826933642637,\n",
       "  9.767413466821319e-05,\n",
       "  4.883706733410659e-05,\n",
       "  2.4418533667053296e-05,\n",
       "  4.883706733410659e-05,\n",
       "  9.767413466821319e-05,\n",
       "  0.00019534826933642637,\n",
       "  0.00039069653867285274,\n",
       "  0.0007813930773457055],\n",
       " [0.0007813930773457055,\n",
       "  0.001562786154691411,\n",
       "  0.003125572309382822,\n",
       "  0.006251144618765644,\n",
       "  0.012502289237531288,\n",
       "  0.025004578475062576,\n",
       "  0.05000915695012515,\n",
       "  0.1000183139002503,\n",
       "  0.6,\n",
       "  0.1000183139002503,\n",
       "  0.05000915695012515,\n",
       "  0.025004578475062576,\n",
       "  0.012502289237531288,\n",
       "  0.006251144618765644,\n",
       "  0.003125572309382822,\n",
       "  0.001562786154691411,\n",
       "  0.0007813930773457055,\n",
       "  0.00039069653867285274,\n",
       "  0.00019534826933642637,\n",
       "  9.767413466821319e-05,\n",
       "  4.883706733410659e-05,\n",
       "  2.4418533667053296e-05,\n",
       "  4.883706733410659e-05,\n",
       "  9.767413466821319e-05,\n",
       "  0.00019534826933642637,\n",
       "  0.00039069653867285274],\n",
       " [0.0007813930773457055,\n",
       "  0.00039069653867285274,\n",
       "  0.00019534826933642637,\n",
       "  9.767413466821319e-05,\n",
       "  4.883706733410659e-05,\n",
       "  2.4418533667053296e-05,\n",
       "  4.883706733410659e-05,\n",
       "  9.767413466821319e-05,\n",
       "  0.00019534826933642637,\n",
       "  0.00039069653867285274,\n",
       "  0.0007813930773457055,\n",
       "  0.001562786154691411,\n",
       "  0.003125572309382822,\n",
       "  0.006251144618765644,\n",
       "  0.012502289237531288,\n",
       "  0.025004578475062576,\n",
       "  0.05000915695012515,\n",
       "  0.1000183139002503,\n",
       "  0.6,\n",
       "  0.1000183139002503,\n",
       "  0.05000915695012515,\n",
       "  0.025004578475062576,\n",
       "  0.012502289237531288,\n",
       "  0.006251144618765644,\n",
       "  0.003125572309382822,\n",
       "  0.001562786154691411]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observation probability matrix B, \n",
    "# excluding the rows for I and F columns, \n",
    "# exclucing the columns for ReadyToType and EndOfWord\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "matrix_B_List = [ [prCharGiveCharState(char, state_Char) for char in alphabet] \n",
    "                  for state_Char in state_chars]\n",
    "matrix_B_List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001562786154691411"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the observation probability $b_{ij}$\n",
    "i = 0; j =0   #Typing the first character (state_index is 0) in the word but get 'a' generated  \n",
    "matrix_B_List[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003125572309382822"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the observation probability $b_{ij}$\n",
    "i = 0; j =1   #Typing the first character (state_index is 0) in the word but get 'b' generated   \n",
    "matrix_B_List[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use np arrays as data structures instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_pi = np.array( vector_pi_list )\n",
    "matrix_A = np.array( matrix_A_List )\n",
    "matrix_B = np.array( matrix_B_List )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57142857 0.28571429 0.14285714]\n",
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vector_pi)  #Check the shape\n",
    "print(vector_pi.shape)  #Check the shape\n",
    "vector_pi.sum()         #Check the sum of probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(matrix_A.shape)  #Check the shape\n",
    "matrix_A.sum(axis = 1) #Check the sum of probabilties on each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(matrix_B.shape)  #Check the shape\n",
    "matrix_B.sum(axis = 1) #Check the sum of probabilties on each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: You can use lists above as the data structures to implement the work or You may consider using numpy arrays as the data structures to implement the work. Below shows the idea of using Numpy arrays for the implementation of the forward algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToType = \"his\"\n",
    "observedString = \"ab\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 (The column for observing ReadyToType ): Must start at state I (probability 0 for the other states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 (The column for observing 'a'): only keep the real states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.57142857, 0.28571429, 0.14285714])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilties of transitioning into each of the real states from I\n",
    "print( vector_pi.shape)\n",
    "vector_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilties of transitioning into each of the real states from I\n",
    "stage2_1 = vector_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charObserved: a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00156279, 0.00078139, 0.00078139])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilities of observing the first character in each of the real states (excluding F)\n",
    "observationIndex = 0\n",
    "charObserved = observedString[observationIndex]\n",
    "print( \"charObserved:\", charObserved)\n",
    "indexOfObservedChar = ord(charObserved) - ord('a')\n",
    "matrix_B[:, indexOfObservedChar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00089302, 0.00022326, 0.00011163])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two items above to calculate\n",
    "# Probabilities of ending in each of the real states (excluding F) and observing a\n",
    "stage2_2 = stage2_1*matrix_B[:, indexOfObservedChar]\n",
    "stage2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 (The column for observing 'b'): only keep the real states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00089302, 0.00022326, 0.00011163])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00089302],\n",
       "       [0.00022326],\n",
       "       [0.00011163]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_2[:, np.newaxis]\n",
    "print( stage2_2[:, np.newaxis].shape )\n",
    "stage2_2[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.78604132e-04, 4.08238016e-04, 2.04119008e-04, 1.02059504e-04],\n",
       "       [0.00000000e+00, 4.46510330e-05, 1.19069421e-04, 5.95347107e-05],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.23255165e-05, 8.93020660e-05]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilties of further transitioning into each of the real states\n",
    "stage3_1 = stage2_2[:, np.newaxis]  * matrix_A\n",
    "stage3_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0001786 , 0.00045289, 0.00034551, 0.0002509 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage3_2 = stage3_1.sum(axis = 0)\n",
    "stage3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0001786 , 0.00045289, 0.00034551])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilities of ending in each of the real states (excluding F)\n",
    "stage3_2[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charObserved: b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00312557, 0.00156279, 0.0003907 ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilities of observing the second character in each of the real states (excluding F)\n",
    "observationIndex = 1\n",
    "charObserved = observedString[observationIndex]\n",
    "print( \"charObserved:\", charObserved)\n",
    "indexOfObservedChar = ord(charObserved) - ord('a')\n",
    "matrix_B[:, indexOfObservedChar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.58240129e-07, 7.07768735e-07, 1.34991103e-07])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two items above to calculate\n",
    "# Probabilities of ending in each of the real states (excluding F) and observing b\n",
    "stage3_3 = stage3_2[:-1]*matrix_B[:, indexOfObservedChar]\n",
    "stage3_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 (The column for observing EndOfWord ): Must be in the Final State F (probability = 0 for the other states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.58240129e-07, 7.07768735e-07, 1.34991103e-07])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities of ending in each of the real states (excluding F) and observing b\n",
    "stage3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11428571, 0.26666667, 0.8       ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities of then transitioning to F from each of the real states\n",
    "matrix_A[:, len( wordToType)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.37988719e-08, 1.88738329e-07, 1.07992882e-07])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two items above to calculate the\n",
    "# Probabilities of then transition to F and ending the typing process of the word\n",
    "# Transisiton to F (index 3 in this case )\n",
    "stage4_1 = stage3_3 * matrix_A[:, len( wordToType)]\n",
    "stage4_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is the sum of all these probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6053008344833416e-07"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = stage4_1.sum()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The result above is also what you would get from the sample demo program for HMMs.\n",
    "# * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 3A_Complete ==> \n",
    "## 1. Define a function prOf1CharSeriesWhenTyping1Word_F to generalize the process (of the forward algorithm) demonstrated in the case above for any given wordToType and any given observedString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the forward algorithm algorithm to determine the probability: \n",
    "# The function should calculate and return\n",
    "#     the probability of getting the string d \n",
    "#     when the user (modelled by the parameter values of pr_hit, pr_repeat, degenerate_kb, ...)\n",
    "#     want to type the word in string w\n",
    "# When the trace is True, the function will report the trace of computation done.\n",
    "\n",
    "def prOf1CharSeriesWhenTyping1Word_F(observedString, wordToType, trace = False):\n",
    "    #The probability distribution after leaving I\n",
    "    vector_pi_list = getPrTableForPossibleInitialStatesGivenTheWord(wordToType)\n",
    "    \n",
    "    #The transition probability matrix A\n",
    "    lenthOfWord = len(wordToType)\n",
    "    matrix_A_List = [ getPrTableForPossibleNextStatesGivenWord(wordToType, currentState) \n",
    "                      for currentState in range(lenthOfWord)]\n",
    "    \n",
    "    #The observation probability matrix B\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    matrix_B_List = [ [prCharGiveCharState(char, state_Char) for char in alphabet] \n",
    "                      for state_Char in wordToType]\n",
    "    \n",
    "    ##############################################\n",
    "    #Cast them into numpy arrays\n",
    "    ##############################################\n",
    "    vector_pi = np.array( vector_pi_list )\n",
    "    matrix_A = np.array( matrix_A_List )\n",
    "    matrix_B = np.array( matrix_B_List )\n",
    "    \n",
    "    if trace == True:\n",
    "        print(\"vector_pi\", vector_pi.shape, \":\\n\", vector_pi)\n",
    "        print(\"matrix_A\", matrix_A.shape, \":\\n\", matrix_A)\n",
    "        print(\"matrix_B\", matrix_B.shape, \":\\n\", matrix_B)\n",
    "    \n",
    "    ##############################################\n",
    "    #For the first column (corresponding to the first character observed)\n",
    "    ##############################################\n",
    "    observationIndex = 0\n",
    "    charObserved = observedString[observationIndex]\n",
    "    if trace == True:\n",
    "        print( \"\\n\\nobservationIndex, charObserved:\", observationIndex, \",\", charObserved)\n",
    "    indexOfObservedCharInAlphabet = ord(charObserved) - ord('a');\n",
    "    \n",
    "    #transitionProbabilties record the 1st-stage results of a column regarding \n",
    "    #    the probabilities of ending in each of the states at this point\n",
    "    transitionProbabilties = vector_pi\n",
    "    if trace == True:\n",
    "        print(\"Probabilties of ending at the states at this point:\\n\", transitionProbabilties)\n",
    "    \n",
    "    #columnProbabilities record the 2nd-stage results of a column regarding \n",
    "    #    the probabilities of ending in each of the states at this point and also\n",
    "    #                         seeing the specific character at this point\n",
    "    observationProbabilities = matrix_B[:, indexOfObservedCharInAlphabet]\n",
    "    if trace == True:\n",
    "        print(\"probabilities of observing \", charObserved, \" at specific states alone:\\n\", \n",
    "              observationProbabilities)\n",
    "\n",
    "    columnProbabilities = transitionProbabilties * observationProbabilities\n",
    "    if trace == True:\n",
    "        print(\"Probabilties of observing up to\", charObserved, \n",
    "              \" and ending at the states at this point:\\n\", columnProbabilities)\n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    # For the remaining columns one at a time\n",
    "    ##############################################\n",
    "    lenthOfObservedString = len(observedString)\n",
    "    for observationIndex in np.arange(1, lenthOfObservedString):\n",
    "        charObserved = observedString[observationIndex]\n",
    "        if trace == True:\n",
    "            print( \"\\nobservationIndex, charObserved:\", observationIndex, \",\", charObserved)\n",
    "        \n",
    "        transitionProbabilties = (columnProbabilities[:, np.newaxis] * matrix_A).sum(axis = 0)\n",
    "        transitionProbabilties = transitionProbabilties[:-1]  # Drop the probability to F\n",
    "        if trace == True:\n",
    "            print(\"Probabilties of ending at the states at this point:\\n\", transitionProbabilties)\n",
    "\n",
    "        indexOfObservedCharInAlphabet = ord(charObserved) - ord('a')\n",
    "        observationProbabilities = matrix_B[:, indexOfObservedCharInAlphabet]\n",
    "        if trace == True:\n",
    "            print(\"probabilities of observing \", charObserved, \" at specific states alone:\\n\", \n",
    "                  observationProbabilities)\n",
    "\n",
    "        columnProbabilities = (transitionProbabilties) * observationProbabilities\n",
    "        if trace == True:\n",
    "            print(\"Probabilties of observing up to\", charObserved, \n",
    "                  \" and ending at the states at this point:\\n\", columnProbabilities)\n",
    "    \n",
    "    ##############################################\n",
    "    # Determine the sum of probabilities of transitioning to the Final state F from each state\n",
    "    ##############################################\n",
    "    if trace == True:\n",
    "        print(\"\\nprobabilities of transitioning to F from states at this point:\\n\", \n",
    "              matrix_A[:, len( wordToType)] )\n",
    "    pr = (columnProbabilities * matrix_A[:, len( wordToType)]).sum()\n",
    "    if trace == True:\n",
    "        print(\"\\nSum of the probabilitie above:\", pr);\n",
    "    \n",
    "    return pr \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_pi (3,) :\n",
      " [0.57142857 0.28571429 0.14285714]\n",
      "matrix_A (3, 4) :\n",
      " [[0.2        0.45714286 0.22857143 0.11428571]\n",
      " [0.         0.2        0.53333333 0.26666667]\n",
      " [0.         0.         0.2        0.8       ]]\n",
      "matrix_B (3, 26) :\n",
      " [[1.56278615e-03 3.12557231e-03 6.25114462e-03 1.25022892e-02\n",
      "  2.50045785e-02 5.00091570e-02 1.00018314e-01 6.00000000e-01\n",
      "  1.00018314e-01 5.00091570e-02 2.50045785e-02 1.25022892e-02\n",
      "  6.25114462e-03 3.12557231e-03 1.56278615e-03 7.81393077e-04\n",
      "  3.90696539e-04 1.95348269e-04 9.76741347e-05 4.88370673e-05\n",
      "  2.44185337e-05 4.88370673e-05 9.76741347e-05 1.95348269e-04\n",
      "  3.90696539e-04 7.81393077e-04]\n",
      " [7.81393077e-04 1.56278615e-03 3.12557231e-03 6.25114462e-03\n",
      "  1.25022892e-02 2.50045785e-02 5.00091570e-02 1.00018314e-01\n",
      "  6.00000000e-01 1.00018314e-01 5.00091570e-02 2.50045785e-02\n",
      "  1.25022892e-02 6.25114462e-03 3.12557231e-03 1.56278615e-03\n",
      "  7.81393077e-04 3.90696539e-04 1.95348269e-04 9.76741347e-05\n",
      "  4.88370673e-05 2.44185337e-05 4.88370673e-05 9.76741347e-05\n",
      "  1.95348269e-04 3.90696539e-04]\n",
      " [7.81393077e-04 3.90696539e-04 1.95348269e-04 9.76741347e-05\n",
      "  4.88370673e-05 2.44185337e-05 4.88370673e-05 9.76741347e-05\n",
      "  1.95348269e-04 3.90696539e-04 7.81393077e-04 1.56278615e-03\n",
      "  3.12557231e-03 6.25114462e-03 1.25022892e-02 2.50045785e-02\n",
      "  5.00091570e-02 1.00018314e-01 6.00000000e-01 1.00018314e-01\n",
      "  5.00091570e-02 2.50045785e-02 1.25022892e-02 6.25114462e-03\n",
      "  3.12557231e-03 1.56278615e-03]]\n",
      "\n",
      "\n",
      "observationIndex, charObserved: 0 , h\n",
      "Probabilties of ending at the states at this point:\n",
      " [0.57142857 0.28571429 0.14285714]\n",
      "probabilities of observing  h  at specific states alone:\n",
      " [6.00000000e-01 1.00018314e-01 9.76741347e-05]\n",
      "Probabilties of observing up to h  and ending at the states at this point:\n",
      " [3.42857143e-01 2.85766611e-02 1.39534478e-05]\n",
      "\n",
      "observationIndex, charObserved: 1 , i\n",
      "Probabilties of ending at the states at this point:\n",
      " [0.06857143 0.16245003 0.09361102]\n",
      "probabilities of observing  i  at specific states alone:\n",
      " [1.00018314e-01 6.00000000e-01 1.95348269e-04]\n",
      "Probabilties of observing up to i  and ending at the states at this point:\n",
      " [6.85839867e-03 9.74700157e-02 1.82867514e-05]\n",
      "\n",
      "observationIndex, charObserved: 2 , s\n",
      "Probabilties of ending at the states at this point:\n",
      " [0.00137168 0.02262927 0.0535553 ]\n",
      "probabilities of observing  s  at specific states alone:\n",
      " [9.76741347e-05 1.95348269e-04 6.00000000e-01]\n",
      "Probabilties of observing up to s  and ending at the states at this point:\n",
      " [1.33977631e-07 4.42058894e-06 3.21331798e-02]\n",
      "\n",
      "probabilities of transitioning to F from states at this point:\n",
      " [0.11428571 0.26666667 0.8       ]\n",
      "\n",
      "Sum of the probabilitie above: 0.02570773798355381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02570773798355381"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With trace\n",
    "prOf1CharSeriesWhenTyping1Word_F(\"his\", \"his\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02570773798355381"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No trace\n",
    "prOf1CharSeriesWhenTyping1Word_F(\"his\", \"his\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.180732321622022e-11"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prOf1CharSeriesWhenTyping1Word_F(\"sadasff\", \"parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a function prOf1CharSeriesWhenTyping1Word_B to implement a brute-force version for any given wordToType and any given observedString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n",
      "[0 1]\n",
      "[0 2]\n",
      "[0 3]\n",
      "[1 0]\n",
      "[1 1]\n",
      "[1 2]\n",
      "[1 3]\n",
      "[2 0]\n",
      "[2 1]\n",
      "[2 2]\n",
      "[2 3]\n",
      "[3 0]\n",
      "[3 1]\n",
      "[3 2]\n",
      "[3 3]\n"
     ]
    }
   ],
   "source": [
    "# A function to return the next state trajectory as a 1 dimensional numpy array\n",
    "def getNextTrajectory(currentTrajectory, sizeOfStateSpace, trace = False):\n",
    "    if np.any(currentTrajectory < sizeOfStateSpace-1) == False: \n",
    "         return np.zeros( currentTrajectory.shape[0] )\n",
    "    \n",
    "    incrementPoint = currentTrajectory.shape[0] -1\n",
    "    while currentTrajectory[incrementPoint] == sizeOfStateSpace-1:\n",
    "        incrementPoint -= 1\n",
    "    if trace: print(\"incrementPoint\", incrementPoint )\n",
    "    nextTrajectory  = currentTrajectory.copy()\n",
    "    nextTrajectory[ incrementPoint  ] += 1\n",
    "    nextTrajectory[ incrementPoint+1:  ] = 0\n",
    "    return nextTrajectory\n",
    "\n",
    "\n",
    "trajectory = np.array([0,0])\n",
    "print( trajectory )\n",
    "for i in np.arange(15):\n",
    "    trajectory = getNextTrajectory(trajectory, 4)\n",
    "    print( trajectory )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "[0 0 1]\n",
      "[0 0 2]\n",
      "[0 0 3]\n",
      "[0 1 0]\n",
      "[0 1 1]\n",
      "[0 1 2]\n",
      "[0 1 3]\n",
      "[0 2 0]\n",
      "[0 2 1]\n",
      "[0 2 2]\n",
      "[0 2 3]\n",
      "[0 3 0]\n",
      "[0 3 1]\n",
      "[0 3 2]\n",
      "[0 3 3]\n",
      "[1 0 0]\n",
      "[1 0 1]\n",
      "[1 0 2]\n",
      "[1 0 3]\n",
      "[1 1 0]\n",
      "[1 1 1]\n",
      "[1 1 2]\n",
      "[1 1 3]\n",
      "[1 2 0]\n",
      "[1 2 1]\n",
      "[1 2 2]\n",
      "[1 2 3]\n",
      "[1 3 0]\n",
      "[1 3 1]\n",
      "[1 3 2]\n",
      "[1 3 3]\n",
      "[2 0 0]\n",
      "[2 0 1]\n",
      "[2 0 2]\n",
      "[2 0 3]\n",
      "[2 1 0]\n",
      "[2 1 1]\n",
      "[2 1 2]\n",
      "[2 1 3]\n",
      "[2 2 0]\n",
      "[2 2 1]\n",
      "[2 2 2]\n",
      "[2 2 3]\n",
      "[2 3 0]\n",
      "[2 3 1]\n",
      "[2 3 2]\n",
      "[2 3 3]\n",
      "[3 0 0]\n",
      "[3 0 1]\n",
      "[3 0 2]\n",
      "[3 0 3]\n",
      "[3 1 0]\n",
      "[3 1 1]\n",
      "[3 1 2]\n",
      "[3 1 3]\n",
      "[3 2 0]\n",
      "[3 2 1]\n",
      "[3 2 2]\n",
      "[3 2 3]\n",
      "[3 3 0]\n",
      "[3 3 1]\n",
      "[3 3 2]\n",
      "[3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# A more efficient variant of the function above:\n",
    "#   transformToNextTrajectory simply updates the contents of current trajectory\n",
    "#   to the next trajectory\n",
    "def transformToNextTrajectory_x(currentTrajectory, sizeOfStateSpace, trace = False):\n",
    "    if np.any(currentTrajectory < sizeOfStateSpace-1) == False: \n",
    "         return np.zeros( currentTrajectory.shape[0] )\n",
    "    \n",
    "    incrementPoint = currentTrajectory.shape[0] -1\n",
    "    while currentTrajectory[incrementPoint] == sizeOfStateSpace-1:\n",
    "        incrementPoint -= 1\n",
    "    if trace: print(\"incrementPoint\", incrementPoint )\n",
    "    currentTrajectory[ incrementPoint  ] += 1\n",
    "    currentTrajectory[ incrementPoint+1:  ] = 0\n",
    "\n",
    "\n",
    "\n",
    "sizeOfStateSpace = 4\n",
    "trajectory = np.array([0,0,0])\n",
    "print( trajectory )\n",
    "while np.all(trajectory == sizeOfStateSpace-1) == False:\n",
    "    transformToNextTrajectory_x(trajectory, sizeOfStateSpace)\n",
    "    print( trajectory )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "[0 0 1]\n",
      "[0 0 2]\n",
      "[0 0 3]\n",
      "[0 1 1]\n",
      "[0 1 2]\n",
      "[0 1 3]\n",
      "[0 2 2]\n",
      "[0 2 3]\n",
      "[0 3 3]\n",
      "[1 1 1]\n",
      "[1 1 2]\n",
      "[1 1 3]\n",
      "[1 2 2]\n",
      "[1 2 3]\n",
      "[1 3 3]\n",
      "[2 2 2]\n",
      "[2 2 3]\n",
      "[2 3 3]\n",
      "[3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# An even more efficient variant of the function above:\n",
    "#   only produce trajectories with non-decreasing state indices inside\n",
    "def transformToNextTrajectory(currentTrajectory, sizeOfStateSpace, trace = False):\n",
    "    if np.any(currentTrajectory < sizeOfStateSpace-1) == False: \n",
    "         return np.zeros( currentTrajectory.shape[0] )\n",
    "    \n",
    "    incrementPoint = currentTrajectory.shape[0] -1\n",
    "    while currentTrajectory[incrementPoint] == sizeOfStateSpace-1:\n",
    "        incrementPoint -= 1\n",
    "    if trace: print(\"incrementPoint\", incrementPoint )\n",
    "    currentTrajectory[ incrementPoint  ] += 1\n",
    "    currentTrajectory[ incrementPoint+1:  ] =  currentTrajectory[ incrementPoint  ]\n",
    "\n",
    "\n",
    "\n",
    "sizeOfStateSpace = 4\n",
    "trajectory = np.array([0,0,0])\n",
    "print( trajectory )\n",
    "while np.all(trajectory == sizeOfStateSpace-1) == False:\n",
    "    transformToNextTrajectory(trajectory, sizeOfStateSpace)\n",
    "    print( trajectory )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the brute-force algorithm to determine the probability: \n",
    "# The function should calculate and return\n",
    "#     the probability of getting the string d \n",
    "#     when the user (modelled by the parameter values of pr_hit, pr_repeat, degenerate_kb, ...)\n",
    "#     want to type the word in string w\n",
    "# When the trace is True, the function will report the trace of computation done.\n",
    "\n",
    "\n",
    "def prOf1CharSeriesWhenTyping1Word_B(observedString, wordToType, trace = False):\n",
    "    #The probability distribution after leaving I\n",
    "    vector_pi_list = getPrTableForPossibleInitialStatesGivenTheWord(wordToType)\n",
    "    \n",
    "    #The transition probability matrix A\n",
    "    lenthOfWord = len(wordToType)\n",
    "    matrix_A_List = [ getPrTableForPossibleNextStatesGivenWord(wordToType, currentState) \n",
    "                      for currentState in range(lenthOfWord)]\n",
    "    \n",
    "    #The observation probability matrix B\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    matrix_B_List = [ [prCharGiveCharState(char, state_Char) for char in alphabet] \n",
    "                      for state_Char in wordToType]\n",
    "    \n",
    "    ##############################################\n",
    "    #Cast them into numpy arrays\n",
    "    ##############################################\n",
    "    vector_pi = np.array( vector_pi_list )\n",
    "    matrix_A = np.array( matrix_A_List )\n",
    "    matrix_B = np.array( matrix_B_List )\n",
    "    \n",
    "    if trace == True:\n",
    "        print(\"vector_pi\", vector_pi.shape, \":\\n\", vector_pi)\n",
    "        print(\"matrix_A\", matrix_A.shape, \":\\n\", matrix_A)\n",
    "        print(\"matrix_B\", matrix_B.shape, \":\\n\", matrix_B)\n",
    "    \n",
    "    #The trajectory should have the same length of observedString.\n",
    "    #Let's start from [0, ..., 0]\n",
    "    sizeOfStateSpace = len( wordToType)\n",
    "    lengthOfTrajectory = len(observedString)\n",
    "    trajectory = np.zeros( lengthOfTrajectory, dtype=\"int32\" ) \n",
    "    pr = 0\n",
    "    \n",
    "    allTrajectoriesExamined = False \n",
    "    while( allTrajectoriesExamined == False):\n",
    "        currentStateIndex = trajectory[ 0 ]\n",
    "        if trace == True:\n",
    "            print(\"type(currentStateIndex )\", type(currentStateIndex ) )\n",
    "            print(\"currentStateIndex=\", currentStateIndex )\n",
    "            print(\"trajectory[ 0 ]=\", trajectory[ 0 ] )\n",
    "        prTrajectory = vector_pi[ currentStateIndex  ]\n",
    "\n",
    "        #Check each observation \n",
    "        for observationIndex in np.arange(0, len(observedString) ): \n",
    "            currentStateIndex = trajectory[ observationIndex ]     \n",
    "                \n",
    "            #Multiply the observation probability\n",
    "            charObserved = observedString[ observationIndex ]\n",
    "            observedCharIndex =  ord(charObserved) -  ord('a')\n",
    "            prTrajectory  *=  matrix_B[ currentStateIndex, observedCharIndex]\n",
    "\n",
    "            #Check whether it is the end of observation\n",
    "            if observationIndex == len(observedString)-1 : \n",
    "                nextStateIndex =  len( wordToType)      #the special final state F as the end\n",
    "            else:\n",
    "                nextStateIndex = trajectory[ observationIndex + 1]  # a regular next state\n",
    "\n",
    "            #Multiply the transition probability to the next state\n",
    "            prTrajectory  *=  matrix_A[ currentStateIndex, nextStateIndex]\n",
    "\n",
    "        #Add the probability of this trajectory and observation to the total probability pr\n",
    "        pr += prTrajectory\n",
    "        \n",
    "        transformToNextTrajectory(trajectory, sizeOfStateSpace)\n",
    "        if np.all(trajectory == (sizeOfStateSpace-1) ):\n",
    "            allTrajectoriesExamined = True\n",
    "    \n",
    "\n",
    "    \n",
    "    return pr \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025707737931218794"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prOf1CharSeriesWhenTyping1Word_B(\"his\", \"his\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3796480158574565e-27"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prOf1CharSeriesWhenTyping1Word_B(\"hsdfsrrerdr\", \"his\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2333754151142193e-10"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prOf1CharSeriesWhenTyping1Word_B(\"paramdguers\", \"parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Programming 3B Probabilistic Reasoning for Identity Recognition\n",
    "\n",
    "def logPrOfGettingDocument1WhenTypingDocument2(document1,document2):\n",
    "\n",
    "    lines1=[]\n",
    "    lines2=[]\n",
    "    pr=0\n",
    "    logsumEBase=0\n",
    "    logsumTBase=0\n",
    "    with open(document1) as f1:\n",
    "        lines1 = f1.read().splitlines()\n",
    "\n",
    "    with open(document2) as f2:\n",
    "        lines2 = f2.read().splitlines()\n",
    "        \n",
    "    for i in range (len(lines1)):\n",
    "        pr=prOf1CharSeriesWhenTyping1Word_F(lines1[i],lines2[i])\n",
    "        logsumEBase += np.log(pr)\n",
    "        logsumTBase += np.log10(pr)\n",
    "\n",
    "    return logsumEBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-439.5404046807038"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters of Johnny\n",
    "pr_hit = 0.9\n",
    "pr_miss = 0.1\n",
    "deg_kb = 2\n",
    "\n",
    "pr_repeat = 0.1\n",
    "pr_moveOn = 0.9\n",
    "deg_sp = 2\n",
    "\n",
    "logPrOfGettingDocument1WhenTypingDocument2('A.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-641.4025369739651"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('B.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-699.6348485807368"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('C.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1063.5549122297623"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('D.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-931.3648640160923"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('E.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-697.3311239291999"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('F.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-633.2059107406498"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('G.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-446.0231356821852"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('H.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-474.2551121768965"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters of Winnie\n",
    "pr_hit = 0.7\n",
    "pr_miss = 0.3\n",
    "deg_kb = 2\n",
    "\n",
    "pr_repeat = 0.1\n",
    "pr_moveOn = 0.9\n",
    "deg_sp = 2\n",
    "\n",
    "logPrOfGettingDocument1WhenTypingDocument2('A.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-612.579738507073"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('B.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-741.9446817984312"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('C.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1009.3924249674283"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('D.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-882.2002539475624"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('E.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-739.2546513390956"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('F.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-610.5605843654805"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('G.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-475.8864122347405"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('H.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-472.1358651513194"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters of Manny\n",
    "pr_hit = 0.9\n",
    "pr_miss = 0.1\n",
    "deg_kb = 2\n",
    "\n",
    "pr_repeat = 0.3\n",
    "pr_moveOn = 0.7\n",
    "deg_sp = 2\n",
    "\n",
    "logPrOfGettingDocument1WhenTypingDocument2('A.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-670.7067379701124"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('B.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-640.6010651341728"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('C.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-976.0387872888258"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('D.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-887.3323815004002"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('E.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-641.9188791377679"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('F.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-651.0236324573995"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('G.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-473.50753787011337"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('H.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-507.0782637104098"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters of Cathy\n",
    "pr_hit = 0.7\n",
    "pr_miss = 0.3\n",
    "deg_kb = 2\n",
    "\n",
    "pr_repeat = 0.3\n",
    "pr_moveOn = 0.7\n",
    "deg_sp = 2\n",
    "\n",
    "logPrOfGettingDocument1WhenTypingDocument2('A.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-643.7515725892246"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('B.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-685.8225115114949"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('C.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-924.4600385213306"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('D.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-841.4990901914263"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('E.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-686.0554791862593"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('F.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-631.4261809240516"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('G.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-504.92036946575115"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('H.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnBestParameterValuesGivenDocument1WhenTypingDocument2(d1,d2):\n",
    "    global pr_hit,pr_miss,pr_repeat,pr_moveOn\n",
    "    pr_hit_saved,pr_miss_saved=pr_hit,pr_miss\n",
    "    pr_repeat_saved,pr_moveOn_saved=pr_repeat,pr_moveOn\n",
    "   \n",
    "    pr_hit_list=np.arange(0.1,1.1,0.1)\n",
    "    pr_repeat_list=np.arange(0.1,1.1,0.1)\n",
    "   \n",
    "\n",
    "    higher_prob=np.NINF\n",
    "   \n",
    "    for hit in pr_hit_list:\n",
    "        pr_hit=hit\n",
    "        pr_miss=1-pr_hit\n",
    "        for repeat in pr_repeat_list:\n",
    "            pr_repeat=repeat\n",
    "            pr_moveOn=1-pr_repeat\n",
    "           \n",
    "            p = logPrOfGettingDocument1WhenTypingDocument2(d1,d2)\n",
    "           \n",
    "            if p > higher_prob:\n",
    "                higher_prob=p\n",
    "                best_pr_hit=pr_hit\n",
    "                best_pr_repeat=pr_repeat\n",
    "    pr_hit,pr_miss=pr_hit_saved,pr_miss_saved\n",
    "    pr_repeat,pr_moveOn=pr_repeat_saved,pr_moveOn_saved\n",
    "    return [best_pr_hit,1-best_pr_hit,best_pr_repeat,1-best_pr_repeat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 4B Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent (document1, document2,stepSize=0.01):\n",
    "    global pr_hit,pr_miss,pr_repeat,pr_moveOn\n",
    "    \n",
    "    pr_hit_saved,pr_miss_saved=pr_hit,pr_miss\n",
    "    pr_repeat_saved,pr_moveOn_saved=pr_repeat,pr_moveOn\n",
    "    \n",
    "    pr_hit=np.random.rand()*0.6+0.2\n",
    "    pr_miss=1-pr_hit\n",
    "    pr_repeat=np.random.rand()*0.6+0.2\n",
    "    pr_moveOn=1-pr_repeat\n",
    "    pr=logPrOfGettingDocument1WhenTypingDocument2(document1,document2)\n",
    "    \n",
    "    searching=True\n",
    "    while searching:\n",
    "        pr_hit_saved2=pr_hit\n",
    "        pr_hit=pr_hit+stepSize\n",
    "        pr_miss=1-pr_hit\n",
    "        pr2=logPrOfGettingDocument1WhenTypingDocument2(document1,document2)\n",
    "        gradient_hit=pr2-pr\n",
    "        pr_hit=pr_hit_saved2\n",
    "        pr_miss=1-pr_hit\n",
    "        \n",
    "        pr_repeat_saved2=pr_repeat\n",
    "        pr_repeat=pr_repeat+stepSize\n",
    "        pr_moveOn=1-pr_repeat\n",
    "        pr2=logPrOfGettingDocument1WhenTypingDocument2(document1,document2)\n",
    "        gradient_repeat=pr2-pr\n",
    "        pr_repeat=pr_repeat_saved2\n",
    "        pr_moveOn=1-pr_repeat\n",
    "        \n",
    "        rate=stepSize/np.sqrt(gradient_hit**2+gradient_repeat**2)\n",
    "        pr_hit=pr_hit+gradient_hit*rate\n",
    "        pr_repeat=pr_repeat+gradient_repeat*rate\n",
    "        pr_miss=1-pr_hit\n",
    "        pr_moveOn=1-pr_repeat\n",
    "        \n",
    "        pr2=logPrOfGettingDocument1WhenTypingDocument2(document1,document2)\n",
    "        difference=pr2-pr\n",
    "        \n",
    "        if difference >= 0.00000001:\n",
    "            pr=pr2\n",
    "            \n",
    "        if difference < 0.00000001:\n",
    "            searching=False\n",
    "            pr_hit=pr_hit_saved2\n",
    "            pr_repeat=pr_repeat_saved2\n",
    "            pr_miss=1-pr_hit\n",
    "            pr_moveOn=1-pr_repeat\n",
    "            \n",
    "        \n",
    "    pr_hit,pr_miss=pr_hit_saved,pr_miss_saved\n",
    "    pr_repeat,pr_moveOn=pr_repeat_saved,pr_moveOn_saved\n",
    "    return (pr_hit_saved2,1-pr_hit_saved2,pr_repeat_saved2,1-pr_repeat_saved2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9170543896210984,\n",
       " 0.08294561037890158,\n",
       " 0.08285622539824317,\n",
       " 0.9171437746017568)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('A.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7220360434274706,\n",
       " 0.27796395657252937,\n",
       " 0.0771313887125728,\n",
       " 0.9228686112874271)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('B.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9101324108899939,\n",
       " 0.08986758911000614,\n",
       " 0.3082043848526873,\n",
       " 0.6917956151473127)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('C.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7017992533586896,\n",
       " 0.29820074664131035,\n",
       " 0.36757381373481157,\n",
       " 0.6324261862651884)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('D.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6976843692879686,\n",
       " 0.3023156307120314,\n",
       " 0.2907899259410318,\n",
       " 0.7092100740589682)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('E.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9077884757424943,\n",
       " 0.09221152425750567,\n",
       " 0.30544506751291167,\n",
       " 0.6945549324870883)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('F.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7383733775908288,\n",
       " 0.26162662240917123,\n",
       " 0.12352476307394838,\n",
       " 0.8764752369260516)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('G.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.909305796812431,\n",
       " 0.09069420318756904,\n",
       " 0.09077879341303285,\n",
       " 0.9092212065869671)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('H.txt','BiolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
